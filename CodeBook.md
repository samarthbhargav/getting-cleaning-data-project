# CodeBook
This document outlines the description of the output of run_analysis.R

Two documents are output by the script: 
* combined.csv
* result.csv

# combined.csv

combined.csv is generated by
* Merging the train and test data of the x, y, and subject.txt files in the test and train sub-directories
* Combining the data columnwise so that each row is a tuple of (subject, x, y)

## Variable Description
* Column 1 : **Subject** Identifies the subject 
* Column 2 : **Y** : one of six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
* Columns 3 onwards: **X** : A 40-feature vector with time and frequency domain variables.

The X features are described below: [1]
The features selected for this database come from the accelerometer and gyroscope 3-axial raw signals tAcc-XYZ and tGyro-XYZ. These time domain signals (prefix 't' to denote time) were captured at a constant rate of 50 Hz. Then they were filtered using a median filter and a 3rd order low pass Butterworth filter with a corner frequency of 20 Hz to remove noise. Similarly, the acceleration signal was then separated into body and gravity acceleration signals (tBodyAcc-XYZ and tGravityAcc-XYZ) using another low pass Butterworth filter with a corner frequency of 0.3 Hz. 

Subsequently, the body linear acceleration and angular velocity were derived in time to obtain Jerk signals (tBodyAccJerk-XYZ and tBodyGyroJerk-XYZ). Also the magnitude of these three-dimensional signals were calculated using the Euclidean norm (tBodyAccMag, tGravityAccMag, tBodyAccJerkMag, tBodyGyroMag, tBodyGyroJerkMag). 

These signals were used to estimate variables of the feature vector for each pattern:  
'-XYZ' is used to denote 3-axial signals in the X, Y and Z directions.

tBodyAcc-XYZ
tGravityAcc-XYZ
tBodyAccJerk-XYZ
tBodyGyro-XYZ
tBodyGyroJerk-XYZ
tBodyAccMag
tGravityAccMag
tBodyAccJerkMag
tBodyGyroMag
tBodyGyroJerkMag
fBodyAcc-XYZ
fBodyAccJerk-XYZ
fBodyGyro-XYZ
fBodyAccMag
fBodyAccJerkMag
fBodyGyroMag
fBodyGyroJerkMag

The set of variables that were estimated from these signals are: 

mean(): Mean value
std(): Standard deviation

Additional vectors obtained by averaging the signals in a signal window sample. These are used on the angle() variable:

gravityMean
tBodyAccMean
tBodyAccJerkMean
tBodyGyroMean
tBodyGyroJerkMean

List of features in combined.csv: (Add 2 to get column number in combined.csv)
	Column	Variable Name
*	3	tBodyAcc-mean()-X
*	4	tBodyAcc-mean()-Y
*	5	tBodyAcc-mean()-Z
*	6	tGravityAcc-mean()-X
*	7	tGravityAcc-mean()-Y
*	8	tGravityAcc-mean()-Z
*	9	tBodyAccJerk-mean()-X
*	10	tBodyAccJerk-mean()-Y
*	11	tBodyAccJerk-mean()-Z
*	12	tBodyGyro-mean()-X
*	13	tBodyGyro-mean()-Y
*	14	tBodyGyro-mean()-Z
*	15	tBodyGyroJerk-mean()-X
*	16	tBodyGyroJerk-mean()-Y
*	17	tBodyGyroJerk-mean()-Z
*	18	tBodyAccMag-mean()
*	19	tGravityAccMag-mean()
*	20	tBodyAccJerkMag-mean()
*	21	tBodyGyroMag-mean()
*	22	tBodyGyroJerkMag-mean()
*	23	tBodyAcc-std()-X,
*	24	tBodyAcc-std()-Y
*	25	tBodyAcc-std()-Z
*	26	tGravityAcc-std()-X
*	27	tGravityAcc-std()-Y
*	28	tGravityAcc-std()-Z
*	29	tBodyAccJerk-std()-X
*	30	tBodyAccJerk-std()-Y
*	31	tBodyAccJerk-std()-Z
*	32	tBodyGyro-std()-X
*	33	tBodyGyro-std()-Y
*	34	tBodyGyro-std()-Z
*	35	tBodyGyroJerk-std()-X
*	36	tBodyGyroJerk-std()-Y
*	37	tBodyGyroJerk-std()-Z
*	38	tBodyAccMag-std()
*	39	tGravityAccMag-std()
*	40	tBodyAccJerkMag-std()
*	41	tBodyGyroMag-std()
*	42	tBodyGyroJerkMag-std()



# result.csv
result.csv is a joined version of combined.csv
* Column 1 : **Subject** Identifies the subject 
* Column 2 : **Y** : one of six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING)
* Columns 3 onwards: **X** : A 40-feature vector with time and frequency domain variables, averaged for a particular activity and Subject. Variable description is the same as above.

# References:
[1] Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012
